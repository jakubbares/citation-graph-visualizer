# LLM Provider: bedrock or deepseek
LLM_PROVIDER=bedrock

# AWS Bedrock Configuration
AWS_REGION=us-east-1
AWS_ACCESS_KEY_ID=your_access_key_here
AWS_SECRET_ACCESS_KEY=your_secret_key_here
BEDROCK_MODEL_ID=us.meta.llama3-3-70b-instruct-v1:0
BEDROCK_MODEL_TEMPERATURE=0.7

# DeepSeek Configuration (alternative to Bedrock)
DEEPSEEK_API_KEY=your_deepseek_api_key_here
DEEPSEEK_MODEL=deepseek-chat

# Optional: Semantic Scholar API Key (for better rate limits)
SEMANTIC_SCHOLAR_API_KEY=

# Application Settings
MAX_PAPERS_IN_GRAPH=200
CACHE_ENABLED=true
CACHE_TTL_SECONDS=86400
